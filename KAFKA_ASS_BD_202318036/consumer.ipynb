{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#KAFKA Assignment\n",
        "\n",
        "Name: Ayush Patel\n",
        "\n",
        "ID : 202318036"
      ],
      "metadata": {
        "id": "8zj-dv-KJ2yV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KRG1aqaFPrN",
        "outputId": "c42f868e-1914-4cd3-8e4d-a8830d072933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting confluent_kafka\n",
            "  Downloading confluent_kafka-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: confluent_kafka\n",
            "Successfully installed confluent_kafka-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install confluent_kafka"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Consumer, KafkaError\n",
        "import json\n",
        "\n",
        "def consume_messages(consumer, topic, data_type):\n",
        "    \"\"\"\n",
        "    Function to consume messages from Kafka topic.\n",
        "\n",
        "    Args:\n",
        "    - consumer: Kafka Consumer object.\n",
        "    - topic: Kafka topic to subscribe to.\n",
        "    - data_type: Type of data being consumed (e.g., 'inventory' or 'delivery').\n",
        "    \"\"\"\n",
        "    # Subscribe to the given topic\n",
        "    consumer.subscribe([topic])\n",
        "\n",
        "    # Consume messages\n",
        "    while True:\n",
        "        msg = consumer.poll(timeout=1.0)  # Poll for messages\n",
        "        if msg is None:\n",
        "            continue\n",
        "        if msg.error():\n",
        "            if msg.error().code() == KafkaError._PARTITION_EOF:\n",
        "                # End of partition\n",
        "                continue\n",
        "            else:\n",
        "                print(f\"Consumer error: {msg.error()}\")\n",
        "                break\n",
        "        # Process message\n",
        "        message_data = json.loads(msg.value().decode('utf-8'))\n",
        "        print(f\"Received {data_type} data:\")\n",
        "        print(json.dumps(message_data, indent=2))  # Print data in formatted JSON\n",
        "        # Perform actions based on the data (e.g., update databases, schedule deliveries)\n",
        "\n",
        "def main():\n",
        "    # Kafka consumer configuration\n",
        "    kafka_config = {'bootstrap.servers': 'localhost:9092'}\n",
        "\n",
        "    # Create Kafka consumer for inventory data\n",
        "    inventory_consumer = Consumer({**kafka_config, 'group.id': 'inventory_group'})\n",
        "    consume_messages(inventory_consumer, 'inventory_orders', 'inventory')\n",
        "\n",
        "    # Create Kafka consumer for delivery data\n",
        "    delivery_consumer = Consumer({**kafka_config, 'group.id': 'delivery_group'})\n",
        "    consume_messages(delivery_consumer, 'delivery_orders', 'delivery')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "I9KxFuxDKcqe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}