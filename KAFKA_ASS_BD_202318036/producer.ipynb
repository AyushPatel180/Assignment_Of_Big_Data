{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#KAFKA Assignment\n",
        "\n",
        "Name: Ayush Patel\n",
        "\n",
        "ID : 202318036"
      ],
      "metadata": {
        "id": "8zj-dv-KJ2yV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KRG1aqaFPrN",
        "outputId": "c42f868e-1914-4cd3-8e4d-a8830d072933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting confluent_kafka\n",
            "  Downloading confluent_kafka-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: confluent_kafka\n",
            "Successfully installed confluent_kafka-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install confluent_kafka"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Producer\n",
        "import json\n",
        "\n",
        "def produce_inventory_order():\n",
        "    # Configure the Kafka producer:\n",
        "    kafka_config = {'bootstrap.servers': 'localhost:9092'}\n",
        "\n",
        "    # Create a new Kafka producer.\n",
        "    producer = Producer(kafka_config)\n",
        "\n",
        "    #Simulate inventory event data (replace with the actual data source).\n",
        "    inventory_events = [\n",
        "        {\"type\": \"inventory\", \"item_id\": \"123\", \"quantity\": 10},\n",
        "        {\"type\": \"inventory\", \"item_id\": \"456\", \"quantity\": 20}\n",
        "    ]\n",
        "\n",
        "    # Send inventory events to the Kafka topic.\n",
        "    for event in inventory_events:\n",
        "        producer.produce('inventory_orders', json.dumps(event).encode('utf-8'))\n",
        "\n",
        "    #  Flush the producer to send messages.\n",
        "    producer.flush()\n",
        "\n",
        "def produce_delivery_order():\n",
        "    # Configure the Kafka producer:\n",
        "    kafka_config = {'bootstrap.servers': 'localhost:9092'}\n",
        "\n",
        "    # Create a new Kafka producer.\n",
        "    producer = Producer(kafka_config)\n",
        "\n",
        "    # Simulate inventory event data (replace with the actual data source).\n",
        "    delivery_events = [\n",
        "        {\"type\": \"delivery\", \"order_id\": \"1001\", \"status\": \"pending\"},\n",
        "        {\"type\": \"delivery\", \"order_id\": \"1002\", \"status\": \"shipped\"}\n",
        "    ]\n",
        "\n",
        "    # Send inventory events to the Kafka topic.\n",
        "    for event in delivery_events:\n",
        "        producer.produce('delivery_orders', json.dumps(event).encode('utf-8'))\n",
        "\n",
        "    #  Flush the producer to send messages.\n",
        "    producer.flush()\n",
        "\n",
        "# Produce inventory and delivery orders\n",
        "produce_inventory_order()\n",
        "produce_delivery_order()\n"
      ],
      "metadata": {
        "id": "I9KxFuxDKcqe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}